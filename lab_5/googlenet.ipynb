{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignoring TF warning messages\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yaduk/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.4993e-02, -2.2940e-01, -3.2330e-01,  5.6914e-02,  1.1345e-01,\n",
      "        -2.8261e-01,  6.1713e-01,  6.1639e-02,  9.4646e-01, -1.4962e+00,\n",
      "        -5.5129e-01, -3.4354e-02, -1.2640e+00, -3.2054e-02,  5.3394e-01,\n",
      "         1.8727e-01,  4.9359e-01, -2.8194e-01, -2.7175e-01, -2.6153e-01,\n",
      "        -3.3352e-01, -7.6689e-02,  6.7201e-02, -5.7018e-01, -5.3244e-01,\n",
      "        -4.9747e-02,  7.1980e-01,  1.1622e+00,  5.1527e-01,  1.3025e+00,\n",
      "         6.8959e-01,  5.5545e-01,  1.3226e-01, -7.1036e-01, -5.0300e-01,\n",
      "        -2.4448e-01, -6.0022e-01,  1.9392e-01, -3.2075e-01,  6.1728e-01,\n",
      "         2.9609e-01, -2.4302e-01,  1.8587e-01, -4.5841e-01,  1.5209e-01,\n",
      "        -6.8352e-01,  9.8970e-01,  6.1482e-01, -1.2936e+00, -4.6710e-01,\n",
      "        -7.0906e-02,  3.1543e-04,  3.7383e-01,  1.8148e-01,  8.5809e-01,\n",
      "         1.0046e+00, -3.0290e-01,  1.9980e-02,  7.7383e-02,  8.1170e-01,\n",
      "         7.7608e-01, -7.0507e-01, -2.2673e-01, -2.5853e-01,  1.5494e-01,\n",
      "        -4.5743e-01,  7.8234e-01,  1.4158e-01,  1.0213e+00, -6.3676e-01,\n",
      "         3.6661e-01, -8.5761e-01,  8.9956e-01,  2.4746e-01,  5.8414e-01,\n",
      "         7.4481e-02,  2.3752e-02, -1.4097e-01,  1.2139e+00,  2.1882e-01,\n",
      "        -4.8006e-01,  2.7859e-02,  5.7726e-01, -7.9288e-01,  2.0504e-01,\n",
      "        -1.3443e+00, -5.3029e-01, -9.1339e-01, -1.0377e+00,  1.2086e+00,\n",
      "         6.7443e-01, -9.7692e-01, -6.2002e-01, -8.3615e-01, -7.9509e-01,\n",
      "        -9.8087e-02, -4.7822e-01, -6.4339e-01, -8.9244e-01,  1.4321e-01,\n",
      "         1.5348e+00, -3.6890e-01,  4.1339e-02, -1.0671e+00,  2.1415e+00,\n",
      "         1.1274e-02,  4.8006e-01, -1.3392e+00, -1.7111e-01, -7.6255e-01,\n",
      "        -8.8018e-03, -1.4415e+00,  7.5324e-01,  1.0299e-01,  9.9480e-01,\n",
      "         7.8983e-01, -5.2784e-01, -1.0770e+00,  1.5088e-01,  1.2638e+00,\n",
      "        -9.0546e-01, -3.5663e-01,  5.3296e-01,  2.3696e-01,  4.6898e-01,\n",
      "         4.2499e-01, -3.2619e-01,  3.7558e-01, -7.7658e-01,  4.1250e-01,\n",
      "        -1.2272e+00, -3.1716e-01,  1.2645e+00, -1.8636e+00, -3.3745e-02,\n",
      "        -2.5264e-01, -1.2178e+00, -1.2274e+00, -1.3595e+00, -6.5222e-01,\n",
      "        -1.0902e+00, -9.2772e-01, -8.1440e-01,  2.3106e-01,  1.2073e-01,\n",
      "        -7.3272e-01,  1.0769e+00, -9.5740e-01, -1.3131e+00, -3.3172e-01,\n",
      "        -1.7445e+00,  8.8447e-01,  2.7566e+00,  2.1522e+00,  2.6072e+00,\n",
      "        -8.3932e-02,  6.9921e-02,  3.2232e+00, -8.2177e-01, -1.1050e+00,\n",
      "        -1.1002e+00, -1.8171e+00, -1.6121e+00, -3.0126e+00, -1.7528e+00,\n",
      "        -1.3873e+00, -1.3428e+00, -2.2511e+00, -1.4985e+00,  8.0174e-01,\n",
      "         2.2144e-01, -1.6764e+00, -1.8992e+00, -5.0052e-01,  1.6311e+00,\n",
      "        -1.2001e+00, -1.6318e+00, -1.1832e+00, -1.5887e+00, -7.8651e-01,\n",
      "        -2.9225e-01, -1.6385e+00, -2.0788e+00, -1.9911e+00, -1.3888e+00,\n",
      "         3.6685e-01,  1.5608e+00, -1.4128e+00, -1.9311e-01, -2.2717e+00,\n",
      "        -1.1323e-01, -2.1200e+00,  1.6612e+00,  5.0225e-01, -8.8228e-01,\n",
      "        -1.0850e+00, -1.9329e+00, -5.3977e-01, -1.4463e+00,  7.3414e-01,\n",
      "         4.4422e-01, -7.7519e-01, -1.5420e+00,  4.7537e+00, -3.7563e-01,\n",
      "        -4.3495e-01, -1.8406e+00,  2.3083e+00,  6.7326e-02, -1.7769e+00,\n",
      "        -2.4650e+00, -1.7887e+00,  2.7516e-01, -1.2040e+00, -7.4290e-01,\n",
      "        -1.0043e-02,  6.5527e-01, -2.2443e-01, -3.4618e-01, -1.4097e+00,\n",
      "        -1.5814e+00, -1.6959e+00,  4.3795e+00,  2.5393e+00,  3.3767e+00,\n",
      "        -1.0299e+00,  9.6450e-01,  8.4907e-02,  9.3303e-01,  2.4948e+00,\n",
      "         3.6314e+00,  3.7901e+00,  3.8142e+00,  2.9007e-01, -2.4561e-01,\n",
      "         8.9610e-01, -2.6604e-01, -1.4106e+00, -6.5542e-01,  8.5582e-01,\n",
      "         6.0448e-01,  6.0195e-01, -1.2353e+00, -1.7816e+00,  1.6682e-01,\n",
      "        -1.5653e+00, -2.5259e+00,  1.0788e+00,  4.7318e+00,  4.2920e+00,\n",
      "         3.9063e+00,  3.9963e-01, -6.3408e-01, -7.8779e-01, -1.0377e+00,\n",
      "        -6.5438e-01,  1.6972e+00,  5.7084e+00,  1.0833e+01,  6.1059e+00,\n",
      "         4.3070e+00,  4.4228e+00, -1.3720e+00,  1.3480e+00,  4.5386e-01,\n",
      "         4.4115e-02, -5.7927e-02,  4.8644e-01, -2.3784e+00,  2.2413e+00,\n",
      "         5.5445e+00, -2.9276e-01, -5.4925e-01,  8.7232e-02,  7.7327e-01,\n",
      "        -2.2291e+00, -1.1817e+00,  5.1878e-01,  1.7801e-02,  5.6996e+00,\n",
      "         3.9967e-01,  6.9066e-01,  5.8662e-01,  3.9759e+00,  1.1045e+00,\n",
      "         2.1431e-01, -9.1743e-01,  1.3669e+00, -4.2799e-01, -2.1457e-01,\n",
      "         2.4096e-02, -6.1850e-01, -6.5320e-02, -6.4883e-01, -2.8097e-01,\n",
      "        -2.0298e-01,  1.2013e+00,  3.4836e-01, -9.2828e-01, -2.7417e-01,\n",
      "         8.4849e-01,  5.0169e-01,  8.5359e-02, -1.8773e-01,  9.1266e-01,\n",
      "        -5.2493e-01,  6.1561e-01, -3.1632e-02, -6.1095e-01, -3.8790e-01,\n",
      "         1.0026e+00,  9.7377e-01,  8.3794e-01,  1.2847e+00,  9.9905e-01,\n",
      "         1.6368e-01,  5.9333e-01,  7.3190e-01,  6.5296e-01,  7.9208e-01,\n",
      "         8.5877e-01,  4.6988e-01, -1.4746e-01,  2.6015e-01,  4.0772e-01,\n",
      "         5.1954e-01,  7.5170e-01,  6.5809e-01, -2.1063e-01,  7.4010e-01,\n",
      "        -1.3736e+00, -1.8990e-01,  2.8424e+00,  1.7767e+00, -1.1780e-01,\n",
      "         5.9482e-01,  2.4220e-01, -4.9318e-01,  9.3614e-01,  1.1296e-01,\n",
      "         1.2151e-01,  9.8038e-02, -1.0674e+00, -1.7694e+00, -1.6688e+00,\n",
      "        -6.4346e-01, -8.1224e-01, -6.0543e-01, -3.2006e-01, -2.1043e+00,\n",
      "        -1.5606e+00, -1.2761e+00, -2.1196e+00, -8.7401e-01, -1.5696e+00,\n",
      "         7.5334e-01,  8.2180e-01, -1.5169e-01,  1.1159e+00,  6.5333e-01,\n",
      "        -1.6292e+00,  1.0338e+00, -6.5634e-01,  1.8704e-01, -1.1071e+00,\n",
      "        -1.4464e+00, -1.1982e+00, -1.4239e+00,  4.1996e-01, -8.1415e-01,\n",
      "        -6.2481e-01, -7.0910e-01, -7.7501e-01,  5.0118e-01,  4.7614e-01,\n",
      "        -1.0947e+00, -1.9218e+00,  9.2934e-01, -1.0048e+00, -1.1548e+00,\n",
      "        -9.9804e-02, -4.6635e-01,  1.4021e-01,  3.6563e-01,  2.3089e-01,\n",
      "        -6.6446e-01, -1.6679e+00,  1.4618e+00,  1.7645e+00, -3.2613e-01,\n",
      "        -3.3017e-01, -2.7309e-01, -1.2317e+00, -1.0579e+00, -5.1958e-01,\n",
      "         3.5304e-01, -1.3411e-01, -1.0846e+00,  5.1983e-01, -6.4008e-01,\n",
      "        -1.0243e+00,  8.1099e-02, -4.9096e-01, -7.3699e-01, -2.1578e-01,\n",
      "        -2.5017e-01, -6.5325e-01, -4.8043e-01, -8.0225e-01,  5.0069e-01,\n",
      "         2.4376e-01, -5.9669e-01,  9.0607e-01, -7.0154e-01,  3.1164e-02,\n",
      "         3.2505e-01, -1.6007e-01, -1.9957e-01, -1.8110e-02,  9.6683e-01,\n",
      "        -3.5382e-01, -1.8166e-01, -1.3307e+00, -3.0903e-01, -1.1187e-01,\n",
      "         1.0992e+00, -1.8094e-01,  2.8893e-01, -1.5374e-01,  4.0236e-01,\n",
      "        -1.1513e+00, -7.3021e-01, -2.6487e-01, -4.5103e-01, -1.0710e+00,\n",
      "         9.9181e-01, -4.5242e-01,  6.4731e-02, -5.2307e-01,  5.2441e-01,\n",
      "         3.0398e-01, -1.8014e-02, -4.3408e-01, -1.1370e-01, -2.6530e-01,\n",
      "         5.4607e-01, -3.1370e-01,  2.6148e-01, -2.4133e-01,  6.2499e-01,\n",
      "        -7.7953e-01, -5.4968e-01, -3.7312e-01,  7.6449e-01,  7.7398e-01,\n",
      "         1.1995e+00, -2.7811e-01, -5.3821e-01,  4.2944e-01, -4.3833e-01,\n",
      "         2.5370e-01, -6.6250e-01,  3.8797e-01,  1.0276e+00, -6.3764e-01,\n",
      "        -2.2089e-01,  6.3266e-02, -6.5754e-01, -5.2642e-01, -9.5180e-01,\n",
      "         3.1144e-01,  5.0106e-01,  6.0192e-01,  6.5883e-01, -5.4482e-01,\n",
      "        -6.6094e-01, -4.5466e-01, -9.3589e-01,  8.8705e-01,  8.6024e-01,\n",
      "        -2.8383e-01, -8.0335e-01, -1.3114e+00,  1.6161e+00,  2.7804e-01,\n",
      "        -1.5633e+00, -3.5996e-01, -7.9601e-01, -3.5529e-01,  1.0321e+00,\n",
      "        -1.1012e+00, -1.0712e+00, -7.2216e-03,  1.0230e-01, -5.7616e-02,\n",
      "         2.2873e-01,  5.7195e-01,  5.4040e-01, -1.0795e+00, -9.2661e-01,\n",
      "        -1.3418e+00, -5.3461e-01,  7.7627e-01, -8.4783e-01, -2.2403e-01,\n",
      "        -5.1444e-01,  6.4819e-02, -8.5031e-02,  2.1077e-01,  8.4629e-01,\n",
      "         3.6521e-01, -6.9152e-01,  2.7565e-02, -5.6347e-01, -3.3247e-01,\n",
      "         1.0947e-01, -5.5628e-01, -6.0172e-01, -1.2084e+00,  5.3640e-01,\n",
      "        -4.8801e-01, -4.1153e-01,  1.2244e+00, -6.9840e-01,  2.4115e-01,\n",
      "         1.0301e-01, -1.5045e-01, -6.7935e-01, -7.9452e-01,  4.5243e-01,\n",
      "        -2.8303e-01,  1.8819e-01, -5.2099e-01, -4.8495e-01,  5.9515e-01,\n",
      "        -5.4320e-01,  1.5637e-01, -4.7146e-02, -5.8853e-01,  2.6952e+00,\n",
      "        -1.3571e+00,  6.0433e-01,  6.7799e-01, -3.2858e-01, -8.1805e-01,\n",
      "        -1.2194e-02, -7.4953e-01, -6.8558e-01, -2.8887e-01,  3.5132e-01,\n",
      "        -3.9388e-01,  3.2276e-01,  6.3103e-02,  1.5747e-01, -1.3483e+00,\n",
      "        -1.0207e+00, -6.3176e-01,  7.5585e-01, -2.5626e-01,  5.0278e-01,\n",
      "        -4.8085e-01, -6.9669e-01, -6.8120e-01, -2.5710e-01, -3.6672e-01,\n",
      "        -7.9450e-01,  9.3801e-01, -2.1576e-01, -2.8211e-01,  7.7226e-01,\n",
      "        -5.3125e-01, -9.5155e-01, -5.3575e-01, -1.0003e+00,  6.0461e-01,\n",
      "        -3.5079e-01, -8.0551e-01,  4.1619e-01,  4.3679e-01, -2.8340e-01,\n",
      "         1.0776e+00, -3.7695e-01,  3.9271e-01, -7.0575e-01, -2.7473e-01,\n",
      "        -2.4894e-01, -3.5243e-01, -1.9506e-01,  4.2155e-01, -9.0652e-01,\n",
      "        -1.0502e+00, -5.5407e-01, -9.9822e-01, -8.6723e-02, -3.7668e-01,\n",
      "         4.5372e-01,  9.6342e-01, -6.7468e-01, -2.6129e-01,  1.2028e-01,\n",
      "        -7.7148e-01, -5.4487e-02, -3.8340e-01, -5.5097e-01,  1.7922e-02,\n",
      "        -9.1831e-01, -3.3737e-01, -3.7203e-01, -5.1985e-01, -7.5259e-01,\n",
      "        -7.0570e-01,  6.6889e-01, -2.2281e-01, -1.2054e+00,  8.8167e-01,\n",
      "        -7.6244e-01, -1.8608e+00, -4.4351e-01, -7.3197e-01, -7.5008e-01,\n",
      "        -1.7475e-01,  1.1151e+00,  8.5394e-01,  2.7274e-01,  6.6123e-01,\n",
      "        -1.4083e-01, -2.8765e-01,  1.5086e-01,  6.6013e-01,  5.8444e-01,\n",
      "         7.6633e-01,  1.3559e+00, -2.2464e-01,  9.3990e-01, -1.1201e+00,\n",
      "         3.0295e-01,  8.5669e-01,  7.0354e-01, -5.4959e-02, -2.8341e-01,\n",
      "         6.4181e-01,  4.3870e-01, -4.5822e-01, -1.9184e-01, -3.8110e-02,\n",
      "        -3.0473e-01,  1.0832e+00, -2.4197e-01,  1.2360e-01,  4.8767e-01,\n",
      "        -1.1451e+00, -8.1447e-01,  1.1566e-02,  8.1463e-01, -6.5039e-01,\n",
      "        -3.0620e-02, -2.2235e-01, -2.3763e-01,  4.9378e-01,  1.5565e-01,\n",
      "         4.1627e-01,  2.2409e-02, -1.5079e+00, -1.2915e-01, -5.2457e-02,\n",
      "         1.5920e-01, -2.1122e-01, -7.4720e-01, -8.7486e-01, -5.9243e-01,\n",
      "         5.9310e-01, -2.7730e-01, -1.9327e-01, -5.6936e-01,  2.7528e-01,\n",
      "        -9.3788e-01,  2.1682e-01,  6.7924e-01, -1.0681e+00, -7.9368e-01,\n",
      "        -4.7939e-01, -1.0636e-01, -8.1402e-01, -9.2670e-01, -8.3082e-02,\n",
      "        -3.0964e-01, -5.9462e-01, -6.9761e-01, -7.4472e-01, -5.8947e-01,\n",
      "        -1.3982e+00, -1.5801e+00,  7.7177e-01, -8.1296e-01, -1.0610e-01,\n",
      "         1.4966e-01,  5.4238e-01, -1.8036e-01,  6.5810e-01, -4.4445e-01,\n",
      "         4.0549e-01, -3.3084e-01, -1.0260e+00,  1.3928e+00, -5.2571e-01,\n",
      "        -8.8405e-01,  8.1238e-01, -8.6213e-01, -5.2121e-02, -8.9363e-01,\n",
      "         1.4207e-01,  8.2724e-01, -8.1738e-02, -3.0950e-01, -1.5134e-02,\n",
      "        -1.4231e+00,  1.4264e+00, -8.3317e-01, -5.6547e-01,  7.9054e-01,\n",
      "         1.1580e-01,  1.2074e-01,  6.4458e-01,  1.3617e+00,  5.7749e-01,\n",
      "        -9.5111e-02, -1.6846e+00,  1.7456e-01,  1.1577e+00, -7.3164e-01,\n",
      "         4.1013e-01,  1.6995e-01, -3.8556e-01,  6.8381e-02, -4.4859e-02,\n",
      "        -3.2634e-01, -7.2991e-01, -3.6207e-02,  3.3313e-01, -1.3392e+00,\n",
      "        -9.0643e-01,  6.3786e-04,  2.9423e-01,  4.3054e-01, -6.8161e-01,\n",
      "        -4.7208e-01, -2.1144e-01, -7.8489e-01,  2.6562e-01,  6.3969e-01,\n",
      "         5.3968e-01, -3.6081e-01, -7.9117e-02,  1.0851e+00, -1.0600e+00,\n",
      "         6.4262e-01,  7.6461e-01, -5.6500e-01,  1.4236e-01,  5.3051e-01,\n",
      "         7.0624e-01,  3.1811e-01, -4.4601e-02,  2.9455e-01, -1.3785e-01,\n",
      "         2.8429e-01,  6.7749e-02, -9.9836e-02,  4.6914e-01, -7.4812e-02,\n",
      "         1.4254e-01, -6.5597e-02,  3.1007e-01, -1.0822e-01,  6.8708e-01,\n",
      "        -4.1983e-01, -3.7365e-01, -1.0560e-01, -2.1573e-01, -2.2811e-01,\n",
      "         1.3339e-01, -4.0239e-01,  1.4971e-01,  7.8981e-01, -5.2404e-01,\n",
      "        -1.4654e+00,  1.2222e-01, -6.1212e-01,  1.2921e+00,  7.4323e-01,\n",
      "        -7.8365e-01, -3.7320e-01,  4.1597e-01, -6.8846e-01, -2.1501e-01,\n",
      "        -1.0435e+00, -1.2024e+00, -4.6527e-01, -9.0136e-01,  8.5704e-01,\n",
      "         7.9300e-02, -1.1768e+00, -1.1218e+00, -1.3060e+00,  4.7997e-01,\n",
      "         1.3086e+00,  6.7575e-01,  1.8511e-01, -1.0490e+00, -1.3899e+00,\n",
      "         2.3416e-01,  9.0438e-01, -1.8188e+00,  2.4058e-01, -9.0280e-03,\n",
      "         1.5263e+00, -3.4697e-01, -4.3517e-01,  2.3463e-01, -1.1202e+00,\n",
      "         1.2970e-01, -5.4539e-01, -2.2633e-01,  2.0815e-01,  3.7689e-02,\n",
      "         7.9618e-01,  5.8095e-01, -5.9446e-01,  4.0432e-01, -2.9156e-01,\n",
      "        -1.5056e+00,  2.0647e-01, -4.5628e-01, -7.4923e-01, -6.1570e-01,\n",
      "        -1.7241e-01, -1.1715e-01, -1.2502e-01,  1.1987e+00, -5.4955e-01,\n",
      "        -1.0523e+00, -4.0537e-01, -3.5223e-01,  5.1154e-01, -3.1331e-01,\n",
      "         3.8629e-01, -1.0327e+00, -1.9777e-01, -8.8497e-01, -3.2794e-01,\n",
      "         2.5116e-01, -7.2507e-01,  1.4095e+00,  9.5063e-01, -3.6117e-01,\n",
      "         2.6250e-01, -9.1477e-01, -7.4292e-01,  1.1225e+00, -6.7355e-01,\n",
      "         6.5289e-01,  6.7227e-01, -8.5243e-01, -4.5101e-01, -7.7795e-01,\n",
      "         7.1366e-02,  5.0793e-01, -4.9210e-01,  2.0165e-01,  1.9123e-01,\n",
      "         1.0325e+00,  5.2674e-03,  5.6489e-02, -9.7009e-01, -4.0209e-01,\n",
      "        -5.0601e-01,  1.1532e+00,  1.5548e-02,  1.6346e-01,  6.4434e-01,\n",
      "        -3.7269e-01, -1.4364e-01,  3.5481e-02, -3.9402e-01, -1.0359e-01,\n",
      "         1.9565e-01,  4.2431e-01, -9.9716e-01,  2.1071e-01, -9.3277e-01,\n",
      "        -1.0218e+00, -5.6073e-01,  5.4656e-01,  6.4665e-02, -5.2343e-01,\n",
      "        -7.7910e-01,  3.0579e-01,  6.0874e-01, -3.8170e-01,  5.0500e-02,\n",
      "        -1.7593e-01, -5.3471e-01,  8.7648e-01, -3.7254e-01,  1.4352e+00,\n",
      "         9.8639e-01, -7.8076e-01, -1.8595e-01, -6.5459e-03, -7.9449e-01,\n",
      "        -3.9697e-01, -1.4813e-01,  1.3126e+00,  1.9907e-01, -7.9541e-01,\n",
      "        -1.0497e+00,  5.2691e-01, -1.0969e+00,  1.9994e-01, -4.2997e-01,\n",
      "         2.6888e-01, -3.9056e-01,  1.8439e-01, -2.8387e-01, -5.6801e-03,\n",
      "         1.1489e-01, -2.9964e-01, -1.9738e-01, -9.3881e-01,  1.5063e+00,\n",
      "         1.3276e-01, -6.5759e-01,  8.5279e-02, -5.6569e-01, -9.1921e-01,\n",
      "        -1.0209e-01,  3.9747e-01,  5.7433e-01,  8.5791e-01,  4.5863e-01,\n",
      "        -8.8756e-01, -9.2246e-01, -4.1318e-01,  8.6781e-01,  2.2817e-01,\n",
      "        -2.0735e-02,  1.1186e+00,  5.0974e-01,  1.0116e+00,  1.2312e+00,\n",
      "        -6.8063e-02,  7.2177e-01, -4.8849e-01,  7.2173e-01, -5.8577e-01,\n",
      "         2.3100e-02,  7.9391e-01,  1.0289e+00,  6.9655e-01, -1.1150e+00,\n",
      "        -1.4507e+00,  6.0507e-01, -5.1852e-01, -2.3989e-01, -4.6484e-01,\n",
      "        -1.1129e+00, -7.3214e-01,  2.8075e-02, -3.9467e-02,  1.7322e-01,\n",
      "         7.7684e-01, -1.5125e-01, -7.5896e-02, -3.8641e-01,  4.7813e-01,\n",
      "         1.3230e+00,  4.8432e-01,  6.9391e-01,  3.0361e-01,  4.4202e-01,\n",
      "         2.3565e-01, -1.7147e-01,  6.4282e-01, -1.2218e-02,  1.2948e+00,\n",
      "         3.3125e-01,  9.0843e-01, -5.6557e-02,  1.9310e-01,  9.3817e-01,\n",
      "         1.7254e+00,  2.4770e-01,  8.6656e-01, -1.0737e+00, -3.1986e-01,\n",
      "         1.0485e-01, -4.5614e-01, -4.7298e-01,  2.9650e-01,  3.0001e-01],\n",
      "       device='cuda:0')\n",
      "tensor([1.9172e-05, 1.4718e-05, 1.3399e-05, 1.9597e-05, 2.0737e-05, 1.3955e-05,\n",
      "        3.4315e-05, 1.9690e-05, 4.7700e-05, 4.1464e-06, 1.0667e-05, 1.7888e-05,\n",
      "        5.2300e-06, 1.7929e-05, 3.1576e-05, 2.2326e-05, 3.0327e-05, 1.3965e-05,\n",
      "        1.4108e-05, 1.4253e-05, 1.3263e-05, 1.7146e-05, 1.9800e-05, 1.0468e-05,\n",
      "        1.0870e-05, 1.7614e-05, 3.8026e-05, 5.9183e-05, 3.0992e-05, 6.8097e-05,\n",
      "        3.6894e-05, 3.2263e-05, 2.1131e-05, 9.0985e-06, 1.1195e-05, 1.4498e-05,\n",
      "        1.0158e-05, 2.2475e-05, 1.3433e-05, 3.4321e-05, 2.4892e-05, 1.4519e-05,\n",
      "        2.2294e-05, 1.1705e-05, 2.1554e-05, 9.3460e-06, 4.9808e-05, 3.4236e-05,\n",
      "        5.0778e-06, 1.1604e-05, 1.7246e-05, 1.8519e-05, 2.6905e-05, 2.2197e-05,\n",
      "        4.3666e-05, 5.0554e-05, 1.3675e-05, 1.8886e-05, 2.0002e-05, 4.1686e-05,\n",
      "        4.0227e-05, 9.1468e-06, 1.4757e-05, 1.4295e-05, 2.1615e-05, 1.1717e-05,\n",
      "        4.0480e-05, 2.1329e-05, 5.1407e-05, 9.7934e-06, 2.6711e-05, 7.8527e-06,\n",
      "        4.5514e-05, 2.3711e-05, 3.3202e-05, 1.9944e-05, 1.8958e-05, 1.6079e-05,\n",
      "        6.2328e-05, 2.3041e-05, 1.1455e-05, 1.9036e-05, 3.2974e-05, 8.3779e-06,\n",
      "        2.2726e-05, 4.8269e-06, 1.0894e-05, 7.4267e-06, 6.5587e-06, 6.1994e-05,\n",
      "        3.6339e-05, 6.9695e-06, 9.9587e-06, 8.0231e-06, 8.3593e-06, 1.6783e-05,\n",
      "        1.1476e-05, 9.7287e-06, 7.5839e-06, 2.1363e-05, 8.5911e-05, 1.2802e-05,\n",
      "        1.9294e-05, 6.3685e-06, 1.5758e-04, 1.8723e-05, 2.9920e-05, 4.8512e-06,\n",
      "        1.5601e-05, 8.6358e-06, 1.8351e-05, 4.3795e-06, 3.9319e-05, 2.0521e-05,\n",
      "        5.0062e-05, 4.0784e-05, 1.0920e-05, 6.3057e-06, 2.1528e-05, 6.5516e-05,\n",
      "        7.4858e-06, 1.2960e-05, 3.1545e-05, 2.3463e-05, 2.9590e-05, 2.8317e-05,\n",
      "        1.3360e-05, 2.6952e-05, 8.5155e-06, 2.7965e-05, 5.4264e-06, 1.3481e-05,\n",
      "        6.5563e-05, 2.8717e-06, 1.7899e-05, 1.4380e-05, 5.4773e-06, 5.4252e-06,\n",
      "        4.7540e-06, 9.6432e-06, 6.2234e-06, 7.3210e-06, 8.1995e-06, 2.3325e-05,\n",
      "        2.0888e-05, 8.8973e-06, 5.4345e-05, 7.1069e-06, 4.9797e-06, 1.3286e-05,\n",
      "        3.2349e-06, 4.4833e-05, 2.9151e-04, 1.5928e-04, 2.5106e-04, 1.7022e-05,\n",
      "        1.9854e-05, 4.6485e-04, 8.1392e-06, 6.1316e-06, 6.1609e-06, 3.0082e-06,\n",
      "        3.6926e-06, 9.1019e-07, 3.2080e-06, 4.6235e-06, 4.8337e-06, 1.9491e-06,\n",
      "        4.1369e-06, 4.1273e-05, 2.3102e-05, 3.4627e-06, 2.7711e-06, 1.1223e-05,\n",
      "        9.4592e-05, 5.5754e-06, 3.6208e-06, 5.6703e-06, 3.7801e-06, 8.4314e-06,\n",
      "        1.3821e-05, 3.5965e-06, 2.3155e-06, 2.5279e-06, 4.6165e-06, 2.6717e-05,\n",
      "        8.8166e-05, 4.5071e-06, 1.5262e-05, 1.9093e-06, 1.6531e-05, 2.2221e-06,\n",
      "        9.7481e-05, 3.0591e-05, 7.6613e-06, 6.2554e-06, 2.6793e-06, 1.0791e-05,\n",
      "        4.3586e-06, 3.8575e-05, 2.8867e-05, 8.5274e-06, 3.9609e-06, 2.1476e-03,\n",
      "        1.2716e-05, 1.1983e-05, 2.9384e-06, 1.8619e-04, 1.9802e-05, 3.1315e-06,\n",
      "        1.5737e-06, 3.0948e-06, 2.4377e-05, 5.5535e-06, 8.8072e-06, 1.8328e-05,\n",
      "        3.5650e-05, 1.4791e-05, 1.3096e-05, 4.5212e-06, 3.8077e-06, 3.3959e-06,\n",
      "        1.4773e-03, 2.3456e-04, 5.4193e-04, 6.6099e-06, 4.8568e-05, 2.0153e-05,\n",
      "        4.7064e-05, 2.2436e-04, 6.9916e-04, 8.1942e-04, 8.3936e-04, 2.4743e-05,\n",
      "        1.4481e-05, 4.5357e-05, 1.4188e-05, 4.5171e-06, 9.6124e-06, 4.3566e-05,\n",
      "        3.3884e-05, 3.3799e-05, 5.3824e-06, 3.1171e-06, 2.1874e-05, 3.8696e-06,\n",
      "        1.4808e-06, 5.4447e-05, 2.1012e-03, 1.3536e-03, 9.2040e-04, 2.7608e-05,\n",
      "        9.8197e-06, 8.4206e-06, 6.5584e-06, 9.6223e-06, 1.0105e-04, 5.5797e-03,\n",
      "        9.3789e-01, 8.3034e-03, 1.3740e-03, 1.5426e-03, 4.6948e-06, 7.1268e-05,\n",
      "        2.9146e-05, 1.9348e-05, 1.7471e-05, 3.0112e-05, 1.7161e-06, 1.7413e-04,\n",
      "        4.7360e-03, 1.3814e-05, 1.0689e-05, 2.0200e-05, 4.0114e-05, 1.9924e-06,\n",
      "        5.6791e-06, 3.1101e-05, 1.8845e-05, 5.5304e-03, 2.7609e-05, 3.6934e-05,\n",
      "        3.3284e-05, 9.8667e-04, 5.5865e-05, 2.2937e-05, 7.3967e-06, 7.2629e-05,\n",
      "        1.2067e-05, 1.4938e-05, 1.8964e-05, 9.9739e-06, 1.7342e-05, 9.6759e-06,\n",
      "        1.3978e-05, 1.5112e-05, 6.1547e-05, 2.6228e-05, 7.3169e-06, 1.4074e-05,\n",
      "        4.3248e-05, 3.0574e-05, 2.0163e-05, 1.5344e-05, 4.6114e-05, 1.0952e-05,\n",
      "        3.4263e-05, 1.7936e-05, 1.0049e-05, 1.2561e-05, 5.0453e-05, 4.9021e-05,\n",
      "        4.2794e-05, 6.6899e-05, 5.0276e-05, 2.1805e-05, 3.3509e-05, 3.8489e-05,\n",
      "        3.5567e-05, 4.0876e-05, 4.3695e-05, 2.9617e-05, 1.5975e-05, 2.4013e-05,\n",
      "        2.7832e-05, 3.1125e-05, 3.9259e-05, 3.5750e-05, 1.4997e-05, 3.8806e-05,\n",
      "        4.6871e-06, 1.5311e-05, 3.1764e-04, 1.0942e-04, 1.6456e-05, 3.3558e-05,\n",
      "        2.3586e-05, 1.1306e-05, 4.7210e-05, 2.0727e-05, 2.0905e-05, 2.0420e-05,\n",
      "        6.3667e-06, 3.1551e-06, 3.4893e-06, 9.7280e-06, 8.2172e-06, 1.0105e-05,\n",
      "        1.3442e-05, 2.2573e-06, 3.8881e-06, 5.1676e-06, 2.2231e-06, 7.7250e-06,\n",
      "        3.8529e-06, 3.9323e-05, 4.2109e-05, 1.5907e-05, 5.6508e-05, 3.5581e-05,\n",
      "        3.6300e-06, 5.2055e-05, 9.6035e-06, 2.2321e-05, 6.1185e-06, 4.3584e-06,\n",
      "        5.5860e-06, 4.4575e-06, 2.8175e-05, 8.2015e-06, 9.9111e-06, 9.1100e-06,\n",
      "        8.5289e-06, 3.0559e-05, 2.9803e-05, 6.1951e-06, 2.7093e-06, 4.6890e-05,\n",
      "        6.7779e-06, 5.8338e-06, 1.6754e-05, 1.1613e-05, 2.1299e-05, 2.6685e-05,\n",
      "        2.3321e-05, 9.5258e-06, 3.4925e-06, 7.9859e-05, 1.0809e-04, 1.3361e-05,\n",
      "        1.3307e-05, 1.4089e-05, 5.4021e-06, 6.4272e-06, 1.1011e-05, 2.6351e-05,\n",
      "        1.6189e-05, 6.2579e-06, 3.1134e-05, 9.7610e-06, 6.6472e-06, 2.0077e-05,\n",
      "        1.1331e-05, 8.8594e-06, 1.4920e-05, 1.4415e-05, 9.6332e-06, 1.1451e-05,\n",
      "        8.2997e-06, 3.0544e-05, 2.3623e-05, 1.0194e-05, 4.5812e-05, 9.1790e-06,\n",
      "        1.9099e-05, 2.5624e-05, 1.5775e-05, 1.5164e-05, 1.8181e-05, 4.8682e-05,\n",
      "        1.2996e-05, 1.5438e-05, 4.8926e-06, 1.3591e-05, 1.6554e-05, 5.5572e-05,\n",
      "        1.5449e-05, 2.4715e-05, 1.5875e-05, 2.7683e-05, 5.8544e-06, 8.9197e-06,\n",
      "        1.4205e-05, 1.1792e-05, 6.3437e-06, 4.9913e-05, 1.1776e-05, 1.9751e-05,\n",
      "        1.0973e-05, 3.1277e-05, 2.5089e-05, 1.8182e-05, 1.1994e-05, 1.6523e-05,\n",
      "        1.4199e-05, 3.1962e-05, 1.3528e-05, 2.4045e-05, 1.4543e-05, 3.4586e-05,\n",
      "        8.4904e-06, 1.0684e-05, 1.2748e-05, 3.9764e-05, 4.0143e-05, 6.1432e-05,\n",
      "        1.4018e-05, 1.0808e-05, 2.8443e-05, 1.1943e-05, 2.3859e-05, 9.5446e-06,\n",
      "        2.7288e-05, 5.1730e-05, 9.7847e-06, 1.4844e-05, 1.9722e-05, 9.5920e-06,\n",
      "        1.0936e-05, 7.1468e-06, 2.5277e-05, 3.0555e-05, 3.3797e-05, 3.5777e-05,\n",
      "        1.0737e-05, 9.5594e-06, 1.1749e-05, 7.2615e-06, 4.4949e-05, 4.3760e-05,\n",
      "        1.3938e-05, 8.2905e-06, 4.9883e-06, 9.3179e-05, 2.4447e-05, 3.8773e-06,\n",
      "        1.2916e-05, 8.3516e-06, 1.2977e-05, 5.1963e-05, 6.1548e-06, 6.3424e-06,\n",
      "        1.8380e-05, 2.0507e-05, 1.7476e-05, 2.3271e-05, 3.2800e-05, 3.1781e-05,\n",
      "        6.2903e-06, 7.3291e-06, 4.8390e-06, 1.0847e-05, 4.0235e-05, 7.9298e-06,\n",
      "        1.4797e-05, 1.1068e-05, 1.9753e-05, 1.7004e-05, 2.2856e-05, 4.3153e-05,\n",
      "        2.6674e-05, 9.2715e-06, 1.9030e-05, 1.0538e-05, 1.3277e-05, 2.0655e-05,\n",
      "        1.0614e-05, 1.0143e-05, 5.5293e-06, 3.1654e-05, 1.1364e-05, 1.2267e-05,\n",
      "        6.2984e-05, 9.2079e-06, 2.3561e-05, 2.0522e-05, 1.5927e-05, 9.3851e-06,\n",
      "        8.3641e-06, 2.9105e-05, 1.3949e-05, 2.2346e-05, 1.0995e-05, 1.1399e-05,\n",
      "        3.3570e-05, 1.0754e-05, 2.1646e-05, 1.7660e-05, 1.0277e-05, 2.7414e-04,\n",
      "        4.7651e-06, 3.3879e-05, 3.6469e-05, 1.3328e-05, 8.1695e-06, 1.8289e-05,\n",
      "        8.7490e-06, 9.3267e-06, 1.3868e-05, 2.6306e-05, 1.2486e-05, 2.5565e-05,\n",
      "        1.9719e-05, 2.1670e-05, 4.8072e-06, 6.6713e-06, 9.8425e-06, 3.9422e-05,\n",
      "        1.4328e-05, 3.0608e-05, 1.1446e-05, 9.2237e-06, 9.3677e-06, 1.4316e-05,\n",
      "        1.2830e-05, 8.3642e-06, 4.7298e-05, 1.4920e-05, 1.3962e-05, 4.0074e-05,\n",
      "        1.0883e-05, 7.1486e-06, 1.0834e-05, 6.8085e-06, 3.3889e-05, 1.3036e-05,\n",
      "        8.2726e-06, 2.8069e-05, 2.8653e-05, 1.3944e-05, 5.4385e-05, 1.2699e-05,\n",
      "        2.7417e-05, 9.1405e-06, 1.4066e-05, 1.4433e-05, 1.3014e-05, 1.5232e-05,\n",
      "        2.8220e-05, 7.4779e-06, 6.4769e-06, 1.0638e-05, 6.8226e-06, 1.6975e-05,\n",
      "        1.2702e-05, 2.9142e-05, 4.8516e-05, 9.4290e-06, 1.4256e-05, 2.0879e-05,\n",
      "        8.5590e-06, 1.7531e-05, 1.2617e-05, 1.0671e-05, 1.8848e-05, 7.3902e-06,\n",
      "        1.3212e-05, 1.2762e-05, 1.1008e-05, 8.7223e-06, 9.1410e-06, 3.6138e-05,\n",
      "        1.4815e-05, 5.5462e-06, 4.4707e-05, 8.6367e-06, 2.8795e-06, 1.1881e-05,\n",
      "        8.9040e-06, 8.7442e-06, 1.5545e-05, 5.6464e-05, 4.3485e-05, 2.4318e-05,\n",
      "        3.5863e-05, 1.6081e-05, 1.3885e-05, 2.1527e-05, 3.5823e-05, 3.3212e-05,\n",
      "        3.9837e-05, 7.1833e-05, 1.4788e-05, 4.7388e-05, 6.0399e-06, 2.5064e-05,\n",
      "        4.3605e-05, 3.7413e-05, 1.7523e-05, 1.3944e-05, 3.5173e-05, 2.8708e-05,\n",
      "        1.1708e-05, 1.5281e-05, 1.7821e-05, 1.3650e-05, 5.4691e-05, 1.4534e-05,\n",
      "        2.0948e-05, 3.0148e-05, 5.8906e-06, 8.1989e-06, 1.8728e-05, 4.1808e-05,\n",
      "        9.6608e-06, 1.7955e-05, 1.4822e-05, 1.4597e-05, 3.0333e-05, 2.1631e-05,\n",
      "        2.8071e-05, 1.8932e-05, 4.0981e-06, 1.6270e-05, 1.7567e-05, 2.1708e-05,\n",
      "        1.4988e-05, 8.7693e-06, 7.7184e-06, 1.0237e-05, 3.3501e-05, 1.4030e-05,\n",
      "        1.5259e-05, 1.0476e-05, 2.4380e-05, 7.2470e-06, 2.2995e-05, 3.6514e-05,\n",
      "        6.3623e-06, 8.3711e-06, 1.1463e-05, 1.6645e-05, 8.2026e-06, 7.3285e-06,\n",
      "        1.7037e-05, 1.3583e-05, 1.0215e-05, 9.2152e-06, 8.7911e-06, 1.0268e-05,\n",
      "        4.5736e-06, 3.8128e-06, 4.0054e-05, 8.2112e-06, 1.6649e-05, 2.1502e-05,\n",
      "        3.1844e-05, 1.5458e-05, 3.5750e-05, 1.1870e-05, 2.7770e-05, 1.3298e-05,\n",
      "        6.6360e-06, 7.4537e-05, 1.0944e-05, 7.6478e-06, 4.1714e-05, 7.8173e-06,\n",
      "        1.7573e-05, 7.5749e-06, 2.1339e-05, 4.2339e-05, 1.7060e-05, 1.3585e-05,\n",
      "        1.8235e-05, 4.4609e-06, 7.7081e-05, 8.0470e-06, 1.0517e-05, 4.0813e-05,\n",
      "        2.0786e-05, 2.0889e-05, 3.5271e-05, 7.2250e-05, 3.2982e-05, 1.6833e-05,\n",
      "        3.4346e-06, 2.2044e-05, 5.8918e-05, 8.9069e-06, 2.7899e-05, 2.1942e-05,\n",
      "        1.2590e-05, 1.9823e-05, 1.7701e-05, 1.3358e-05, 8.9224e-06, 1.7855e-05,\n",
      "        2.5831e-05, 4.8512e-06, 7.4785e-06, 1.8525e-05, 2.4846e-05, 2.8474e-05,\n",
      "        9.3639e-06, 1.1547e-05, 1.4985e-05, 8.4450e-06, 2.4145e-05, 3.5098e-05,\n",
      "        3.1758e-05, 1.2906e-05, 1.7105e-05, 5.4793e-05, 6.4139e-06, 3.5201e-05,\n",
      "        3.9769e-05, 1.0522e-05, 2.1345e-05, 3.1468e-05, 3.7514e-05, 2.5447e-05,\n",
      "        1.7705e-05, 2.4854e-05, 1.6129e-05, 2.4600e-05, 1.9811e-05, 1.6754e-05,\n",
      "        2.9595e-05, 1.7178e-05, 2.1349e-05, 1.7337e-05, 2.5243e-05, 1.6614e-05,\n",
      "        3.6802e-05, 1.2166e-05, 1.2741e-05, 1.6658e-05, 1.4920e-05, 1.4737e-05,\n",
      "        2.1155e-05, 1.2380e-05, 2.1503e-05, 4.0783e-05, 1.0962e-05, 4.2761e-06,\n",
      "        2.0920e-05, 1.0038e-05, 6.7394e-05, 3.8927e-05, 8.4555e-06, 1.2747e-05,\n",
      "        2.8063e-05, 9.2999e-06, 1.4931e-05, 6.5207e-06, 5.5627e-06, 1.1625e-05,\n",
      "        7.5166e-06, 4.3620e-05, 2.0041e-05, 5.7067e-06, 6.0295e-06, 5.0154e-06,\n",
      "        2.9917e-05, 6.8516e-05, 3.6387e-05, 2.2277e-05, 6.4851e-06, 4.6115e-06,\n",
      "        2.3397e-05, 4.5734e-05, 3.0032e-06, 2.3548e-05, 1.8346e-05, 8.5177e-05,\n",
      "        1.3085e-05, 1.1981e-05, 2.3408e-05, 6.0393e-06, 2.1077e-05, 1.0730e-05,\n",
      "        1.4763e-05, 2.2797e-05, 1.9224e-05, 4.1044e-05, 3.3096e-05, 1.0217e-05,\n",
      "        2.7738e-05, 1.3831e-05, 4.1079e-06, 2.2758e-05, 1.1730e-05, 8.7516e-06,\n",
      "        1.0002e-05, 1.5581e-05, 1.6466e-05, 1.6337e-05, 6.1383e-05, 1.0686e-05,\n",
      "        6.4632e-06, 1.2343e-05, 1.3017e-05, 3.0877e-05, 1.3533e-05, 2.7242e-05,\n",
      "        6.5915e-06, 1.5191e-05, 7.6408e-06, 1.3337e-05, 2.3799e-05, 8.9657e-06,\n",
      "        7.5786e-05, 4.7899e-05, 1.2901e-05, 2.4070e-05, 7.4164e-06, 8.8070e-06,\n",
      "        5.6880e-05, 9.4397e-06, 3.5565e-05, 3.6261e-05, 7.8935e-06, 1.1792e-05,\n",
      "        8.5038e-06, 1.9882e-05, 3.0766e-05, 1.1318e-05, 2.2649e-05, 2.2414e-05,\n",
      "        5.1984e-05, 1.8611e-05, 1.9589e-05, 7.0173e-06, 1.2384e-05, 1.1161e-05,\n",
      "        5.8655e-05, 1.8803e-05, 2.1800e-05, 3.5262e-05, 1.2753e-05, 1.6036e-05,\n",
      "        1.9182e-05, 1.2484e-05, 1.6691e-05, 2.2514e-05, 2.8298e-05, 6.8299e-06,\n",
      "        2.2855e-05, 7.2841e-06, 6.6638e-06, 1.0567e-05, 3.1977e-05, 1.9750e-05,\n",
      "        1.0969e-05, 8.4941e-06, 2.5135e-05, 3.4029e-05, 1.2639e-05, 1.9472e-05,\n",
      "        1.5526e-05, 1.0846e-05, 4.4476e-05, 1.2755e-05, 7.7763e-05, 4.9643e-05,\n",
      "        8.4799e-06, 1.5371e-05, 1.8392e-05, 8.3643e-06, 1.2447e-05, 1.5964e-05,\n",
      "        6.8792e-05, 2.2591e-05, 8.3566e-06, 6.4805e-06, 3.1355e-05, 6.1816e-06,\n",
      "        2.2610e-05, 1.2043e-05, 2.4224e-05, 1.2527e-05, 2.2262e-05, 1.3938e-05,\n",
      "        1.8408e-05, 2.0767e-05, 1.3720e-05, 1.5197e-05, 7.2403e-06, 8.3492e-05,\n",
      "        2.1141e-05, 9.5915e-06, 2.0161e-05, 1.0515e-05, 7.3836e-06, 1.6716e-05,\n",
      "        2.7548e-05, 3.2878e-05, 4.3657e-05, 2.9286e-05, 7.6210e-06, 7.3597e-06,\n",
      "        1.2247e-05, 4.4092e-05, 2.3258e-05, 1.8133e-05, 5.6658e-05, 3.0821e-05,\n",
      "        5.0911e-05, 6.3412e-05, 1.7295e-05, 3.8101e-05, 1.1359e-05, 3.8099e-05,\n",
      "        1.0306e-05, 1.8946e-05, 4.0951e-05, 5.1800e-05, 3.7152e-05, 6.0706e-06,\n",
      "        4.3397e-06, 3.3904e-05, 1.1023e-05, 1.4564e-05, 1.1630e-05, 6.0837e-06,\n",
      "        8.9024e-06, 1.9040e-05, 1.7796e-05, 2.2014e-05, 4.0258e-05, 1.5914e-05,\n",
      "        1.7160e-05, 1.2579e-05, 2.9862e-05, 6.9508e-05, 3.0048e-05, 3.7054e-05,\n",
      "        2.5080e-05, 2.8803e-05, 2.3432e-05, 1.5596e-05, 3.5209e-05, 1.8288e-05,\n",
      "        6.7579e-05, 2.5783e-05, 4.5920e-05, 1.7495e-05, 2.2456e-05, 4.7306e-05,\n",
      "        1.0395e-04, 2.3716e-05, 4.4037e-05, 6.3267e-06, 1.3445e-05, 2.0559e-05,\n",
      "        1.1732e-05, 1.1536e-05, 2.4902e-05, 2.4990e-05], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download ImageNet labels\n",
    "*!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.9378912448883057\n",
      "Pomeranian 0.008303353562951088\n",
      "Great Pyrenees 0.005579737946391106\n",
      "Arctic fox 0.0055304295383393764\n",
      "white wolf 0.004736033733934164\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item()) #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
