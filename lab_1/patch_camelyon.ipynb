{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943cfaf8-4267-4f8c-861f-088827a6c80f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Yadukrishnan - 21BAI1210\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import os,datetime\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e2836d-ae71-4034-a948-7693564d5470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 04:29:59.415048: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 7.48 GiB (download: 7.48 GiB, generated: Unknown size, total: 7.48 GiB) to /home/u782d71a9465ceb2764971ba7db30605/tensorflow_datasets/patch_camelyon/2.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d927d503e204ef885b98623f47f6714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43280987b662476ebbc107f4938340f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7a957a932a4da9ab9d5e149618dbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/32768 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 04:36:57.300645: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform XPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-19 04:36:57.300695: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:XPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: XPU, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/u782d71a9465ceb2764971ba7db30605/tensorflow_datasets/patch_camelyon/2.0.0.incomplete2RENP7/pat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/262144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/u782d71a9465ceb2764971ba7db30605/tensorflow_datasets/patch_camelyon/2.0.0.incomplete2RENP7/pat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation examples...:   0%|          | 0/32768 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/u782d71a9465ceb2764971ba7db30605/tensorflow_datasets/patch_camelyon/2.0.0.incomplete2RENP7/pat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset patch_camelyon downloaded and prepared to /home/u782d71a9465ceb2764971ba7db30605/tensorflow_datasets/patch_camelyon/2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Loading the data from tensorflow_datasets\n",
    "df, info = tfds.load('patch_camelyon', with_info = True, as_supervised = True)\n",
    "\n",
    "#Getting the train, validation and test data\n",
    "train_data = df['train']\n",
    "valid_data = df['validation']\n",
    "test_data = df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8925693-b574-4f0b-8813-71f4bb439368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to help scale the images\n",
    "def preprocess(image, labels):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255.\n",
    "  return image, labels\n",
    "\n",
    "#Applying the preprocess function we the use of map() method\n",
    "train_data = train_data.map(preprocess)\n",
    "valid_data = valid_data.map(preprocess)\n",
    "test_data = test_data.map(preprocess)\n",
    "\n",
    "#Shuffling the train_data\n",
    "buffer_size = 1000\n",
    "train_data = train_data.shuffle(buffer_size)\n",
    "\n",
    "#Batching and prefetching\n",
    "batch_size = 128\n",
    "train_data = train_data.batch(batch_size).prefetch(1)\n",
    "valid_data = valid_data.batch(batch_size).prefetch(1)\n",
    "test_data = test_data.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "523382f1-c9a8-4142-bef7-478b4ae9dc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 96, 96, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seperating image and label into different variables\n",
    "train_images, train_labels = next(iter(train_data))\n",
    "valid_images, valid_labels = next(iter(valid_data))\n",
    "test_images, test_labels  = next(iter(test_data))\n",
    "\n",
    "#Checking the label shape\n",
    "valid_labels.shape\n",
    "\n",
    "#Checking the image shape\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebc232e-5999-4793-a482-4d01cb95e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = Sequential([\n",
    "                    Conv2D(256, 3,padding='same', kernel_initializer='he_uniform', activation='relu', input_shape = [96, 96, 3]),\n",
    "                    MaxPooling2D(2),\n",
    "                    Conv2D(256, 3,padding='same', kernel_initializer='he_uniform',activation='relu',),\n",
    "                    MaxPooling2D(2),\n",
    "                    Conv2D(512, 3,padding='same',kernel_initializer='he_uniform',activation='relu',),\n",
    "                    MaxPooling2D(2),\n",
    "                    Conv2D(512, 3,padding='same',kernel_initializer='he_uniform',activation='relu',),\n",
    "                    MaxPooling2D(2),\n",
    "                    Conv2D(1024, 3,padding='same', kernel_initializer='he_uniform',activation='relu',),\n",
    "                    MaxPooling2D(2),\n",
    "                    Conv2D(1024, 3,padding='same', kernel_initializer='he_uniform',activation='relu',),\n",
    "                    MaxPooling2D(2),\n",
    "                    Flatten(),\n",
    "                    Dense(1028,kernel_initializer='he_uniform',activation = 'relu'),\n",
    "                    Dense(512,kernel_initializer='he_uniform',activation = 'relu'),\n",
    "                    Dense(128, kernel_initializer='he_uniform',activation = 'relu'),\n",
    "                    Dense(1, activation = 'sigmoid'),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4595d12-010e-450e-b2c8-1cb68f7677ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 04:45:02.030357: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 5s - loss: 1.4346 - acc: 0.5781 - val_loss: 0.6765 - val_acc: 0.6484 - 5s/epoch - 1s/step\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 04:45:06.584018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 1.1134 - acc: 0.4922 - val_loss: 0.6820 - val_acc: 0.5703 - 253ms/epoch - 63ms/step\n",
      "Epoch 3/30\n",
      "4/4 - 0s - loss: 0.6884 - acc: 0.4922 - val_loss: 0.9426 - val_acc: 0.4141 - 254ms/epoch - 64ms/step\n",
      "Epoch 4/30\n",
      "4/4 - 0s - loss: 0.7690 - acc: 0.4219 - val_loss: 0.6854 - val_acc: 0.5312 - 253ms/epoch - 63ms/step\n",
      "Epoch 5/30\n",
      "4/4 - 0s - loss: 0.7037 - acc: 0.5234 - val_loss: 0.6234 - val_acc: 0.5938 - 257ms/epoch - 64ms/step\n",
      "Epoch 6/30\n",
      "4/4 - 0s - loss: 0.6359 - acc: 0.6562 - val_loss: 0.6801 - val_acc: 0.5859 - 248ms/epoch - 62ms/step\n",
      "Epoch 7/30\n",
      "4/4 - 0s - loss: 0.5718 - acc: 0.7109 - val_loss: 0.5712 - val_acc: 0.7109 - 255ms/epoch - 64ms/step\n",
      "Epoch 8/30\n",
      "4/4 - 0s - loss: 0.5779 - acc: 0.6562 - val_loss: 0.5521 - val_acc: 0.7031 - 253ms/epoch - 63ms/step\n",
      "Epoch 9/30\n",
      "4/4 - 0s - loss: 0.5292 - acc: 0.7344 - val_loss: 0.5476 - val_acc: 0.7266 - 247ms/epoch - 62ms/step\n",
      "Epoch 10/30\n",
      "4/4 - 0s - loss: 0.4844 - acc: 0.7812 - val_loss: 0.5463 - val_acc: 0.6953 - 250ms/epoch - 63ms/step\n",
      "Epoch 11/30\n",
      "4/4 - 0s - loss: 0.6132 - acc: 0.6719 - val_loss: 0.7050 - val_acc: 0.5859 - 253ms/epoch - 63ms/step\n",
      "Epoch 12/30\n",
      "4/4 - 0s - loss: 0.5747 - acc: 0.6719 - val_loss: 0.5916 - val_acc: 0.6484 - 255ms/epoch - 64ms/step\n",
      "Epoch 13/30\n",
      "4/4 - 0s - loss: 0.4884 - acc: 0.7734 - val_loss: 0.5133 - val_acc: 0.7422 - 251ms/epoch - 63ms/step\n",
      "Epoch 14/30\n",
      "4/4 - 0s - loss: 0.4260 - acc: 0.8516 - val_loss: 0.5551 - val_acc: 0.7109 - 250ms/epoch - 63ms/step\n",
      "Epoch 15/30\n",
      "4/4 - 0s - loss: 0.4114 - acc: 0.8438 - val_loss: 0.5129 - val_acc: 0.7500 - 259ms/epoch - 65ms/step\n",
      "Epoch 16/30\n",
      "4/4 - 0s - loss: 0.4035 - acc: 0.7891 - val_loss: 0.6253 - val_acc: 0.6562 - 251ms/epoch - 63ms/step\n",
      "Epoch 17/30\n",
      "4/4 - 0s - loss: 0.3900 - acc: 0.8047 - val_loss: 0.5103 - val_acc: 0.7578 - 253ms/epoch - 63ms/step\n",
      "Epoch 18/30\n",
      "4/4 - 0s - loss: 0.3387 - acc: 0.9062 - val_loss: 0.4851 - val_acc: 0.7578 - 255ms/epoch - 64ms/step\n",
      "Epoch 19/30\n",
      "4/4 - 0s - loss: 0.2964 - acc: 0.9219 - val_loss: 0.4805 - val_acc: 0.7812 - 257ms/epoch - 64ms/step\n",
      "Epoch 20/30\n",
      "4/4 - 0s - loss: 0.2634 - acc: 0.9219 - val_loss: 0.6597 - val_acc: 0.6562 - 256ms/epoch - 64ms/step\n",
      "Epoch 21/30\n",
      "4/4 - 0s - loss: 0.2934 - acc: 0.8281 - val_loss: 0.4754 - val_acc: 0.7734 - 253ms/epoch - 63ms/step\n",
      "Epoch 22/30\n",
      "4/4 - 0s - loss: 0.2791 - acc: 0.8984 - val_loss: 0.4902 - val_acc: 0.7500 - 255ms/epoch - 64ms/step\n",
      "Epoch 23/30\n",
      "4/4 - 0s - loss: 0.2196 - acc: 0.9531 - val_loss: 0.5713 - val_acc: 0.6719 - 255ms/epoch - 64ms/step\n",
      "Epoch 24/30\n",
      "4/4 - 0s - loss: 0.1683 - acc: 0.9844 - val_loss: 0.5032 - val_acc: 0.7812 - 252ms/epoch - 63ms/step\n",
      "Epoch 25/30\n",
      "4/4 - 0s - loss: 0.1291 - acc: 0.9766 - val_loss: 0.4747 - val_acc: 0.8047 - 257ms/epoch - 64ms/step\n",
      "Epoch 26/30\n",
      "4/4 - 0s - loss: 0.1059 - acc: 0.9844 - val_loss: 0.5160 - val_acc: 0.7734 - 255ms/epoch - 64ms/step\n",
      "Epoch 27/30\n",
      "4/4 - 0s - loss: 0.0843 - acc: 1.0000 - val_loss: 0.6580 - val_acc: 0.7109 - 257ms/epoch - 64ms/step\n",
      "Epoch 28/30\n",
      "4/4 - 0s - loss: 0.0787 - acc: 0.9922 - val_loss: 0.5684 - val_acc: 0.7734 - 256ms/epoch - 64ms/step\n",
      "Epoch 29/30\n",
      "4/4 - 0s - loss: 0.0659 - acc: 0.9844 - val_loss: 0.5519 - val_acc: 0.7734 - 258ms/epoch - 65ms/step\n",
      "Epoch 30/30\n",
      "4/4 - 0s - loss: 0.0432 - acc: 1.0000 - val_loss: 0.5482 - val_acc: 0.7656 - 259ms/epoch - 65ms/step\n"
     ]
    }
   ],
   "source": [
    "#Compiling our model\n",
    "model.compile(optimizer= optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "#Callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "#Fitting our model\n",
    "history = model.fit( train_images,\n",
    "                    train_labels,\n",
    "                    epochs = 30,\n",
    "                    callbacks=[early_stopping_cb],\n",
    "                    validation_data = (valid_images, valid_labels),\n",
    "                    verbose=2)\n",
    "#21BAI1210"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
